#### 1.1 统计学习

#### 1.2 统计学习的分类
##### 基本分类
- 监督学习 Supervised Learning，指从标注数据中学习预测模型的机器学习问题。监督学习的本质是学习输入到输出的映射的统计规律
	- 将输入与输出所有可能取值的集合分别称为输入空间input space与输出空间output space。输入与输出空间可以是有限元素的结合，也可以是整个欧式空间，可以是同一个空间，也可以是不同空间；但通常输出空间<<<输入空间
		- 每个具体的输入是一个实例instance，由特征向量feature vector表示。所有的特征向量存在的空间称为特征空间feature space。特征空间的每一维对应于一个特征。模型实际上都是定义在特征空间上的。
		- 在监督学习中，将输入与输出看作是定义在输入(特征)空间与输出空间上的随机变量的取值。输入变量为 $X$，输出变量为 $Y$，输入变量的取值写作 $x$，输出变量的取值写作 $y$。
		- 输入实例 $x$ 的特征向量记作 $x=(x^{(1)}, x^{(2)}, \dots, x^{(i)}, \dots, x^{(n)})^T$， $x^{(i)}$ 表示 $x$  的第 $i$ 个特征。监督学习从训练数据training data集合中学习模型，对测试数据test data进行预测。训练数据由输入(或特征向量)与输出对组成，训练集通常表示为 $T=\{(x_1, y_1),(x_2, y_2),\dots,(x_N, y_N)\}$。输入与输出对称为样本sample
		- 回归问题，输入变量与输出变量均为连续变量的预测问题
		- 分类问题，输出变量为有限个离散变量的预测问题
		- 标注问题，输入变量与输出变量均为变量序列的预测问题
	- 联合概率分布。监督学习假设输入与输出的随机变量 $X$ 和 $Y$ 遵循联合概率分布 $P(X, Y)$，它表示分布函数或分布密度函数。训练数据与测试数据被看作是依联合概率分布独立同分布产生的。这是监督学习关于数据的基本假设。
	- 假设空间 hypothesis space，就是模型属于由输入空间到输出空间的映射的集合。监督学习的模型可以是概率模型或非概率模型，由条件概率分布 $P(Y|X)$ 或决策函数decision function  $Y = f(X)$表示，随具体学习方法而定。对具体的输入进行相应的输出预测时，写作 $P(y|x)$ 或 $y = f(X)$
	- 监督学习利用训练数据集学习一个模型，再用模型对测试样本集进行预测。由于标注的训练集是人工给出的，所以称为监督学习。
	- 监督学习分为学习和预测两个过程，由学习系统与预测系统完成。
		- 首先给定一个训练数据集， $T = \{(x_1, y_1), (x_2, y_2),\dots, (x_N, y_N)\}$，其中  $(x_i, y_i), i=1,2,\dots,N$ 是样本或样本点。 $x_i \in X \in \mathbb{R}$是输入得观测值，也称为输入或实例， $y \in Y$ 是输出的观测值，也叫输出
		- 在学习过程中，学习系统利用给定的训练数据集，通过学习/训练得到一个模型，表示为条件概率分布 $\hat{P}(Y|X)$或决策函数 $\hat{Y} = \hat{f}(X)$，都是描述输入与输出随机变量之间的映射关系；
		- 在预测过程中，预测系统对于给定的测试样本集中的输入 $x_{N+1}$，由模型 $y_{N+1} = \mathop{\arg\max}\limits_{y}\hat{P}(y|x_{N+1})$ 或$y_{N+1} = \hat{f}(x_{N+1})$ 给出相应的输出
- 无监督学习 unsupervised learning，是指从无标注数据中学习预测模型的机器学习问题。预测模型表示数据的类别、转换或概率。本质是学习数据中心的统计规律或潜在结构。
	- 假设 $\mathbb{X}$ 是输入空间， $\mathbb{Z}$ 是隐式结构空间。要学习的模型表示为函数 $z = g(x)$ ，条件概率分布 $P(z|x)$ ，或者条件概率分布  $P(x|z)$ 的形式，其中 $x \in \mathbb{X}$ 是输入， $z \in \mathbb{Z}$ 是输出、包含所有可能的魔性的集合是假设空间。无监督学习旨在从假设空间中选出在给定评价标准下的最优模型
	- 训练数据  $U = {x_1, x_2,\dots, x_N}$，其中 $x_i, i=1,2,\dots,N,$是样本
	- 分析时使用学习打得到的模型即 $z = \hat{g}(x)$，条件概率分布 $\hat{P}(z|x)$ 或 $\hat{P}(x|z)$
	- 也分为学习和预测两个过程，由学习系统与预测系统完成。
		- 在学习过程中，学习系统从训练数据集，通过学习/训练得到一个最优模型，表示为函数 $z = g(x)$ ，条件概率分布 $\hat{P}(z|x)$ ，或者条件概率分布  $\hat{P}(x|z)$ 
		- 在预测过程中，预测系统对于给定的输入 $x_{N+1}$，由模型 $z_{N+1} = \hat{g}(x_{N+1})$ 或$z_{N+1} = \mathop{\arg\max}\limits_{z}\hat{P}(z|x_{N+1})$ 或$y_{N+1} = \hat{f}(x_{N+1})$ 给出相应的输出 $z_{N+1}$，进行聚类或降维，或者由模型 $\hat{P}(x|z)$ 给出输入的概率  $\hat{P}(x_{N+1}|z_{N+1})$ 进行概率估计
##### 策略
- 有了模型的假设空间，统计学习接着需要考虑的是按照什么样的准则学习或选择最优的模型。
- 损失函数和风险函数。损失函数度量模型一次预测的好坏，风险函数度量平均意义下模型预测的好坏
	- 用一个损失函数loss function或代价函数cost function来度量预测错误的程度。损失函数是 $L(Y, f(X))$，非负实值函数,Y真实值，f(x)预测值
	- 0-1损失函数， $L(Y, f(X)) = \begin{cases} 1, Y\neq f(X) \\ 0, Y=f(X)\end{cases}$
	- 平方quadratic损失函数，  $L(Y, f(X)) = {(Y - f(X))}^2$
	- 绝对损失函数， $L(Y, f(X)) = |Y - f(X)|$
	- 对数logarithmic损失函数/对数似然log-likelihood损失函数， $L(Y, P(Y|X) = -logP(Y|X)$
	- 损失函数值越小，模型就越好。模型的输入输出XY是随机变量，遵循联合分布P(X,Y)，所以损失函数的期望是 $R_{exp}(f) = E_P[L(Y, f(X))] = \int_{X*Y}{L(y, f(x))P(x, y)dxdy}$，称为**风险函数risk function或期望损失expected loss**
	- 给定一个训练数据集  $T = \{(x_1, y_1), (x_2, y_2),\dots, (x_N, y_N)\}$，模型 $f(X)$ 关于训练数据集的平均损失称为**经验风险empirical risk或经验损失 empirical loss，记作 $R_{emp}(f) = \frac{1}{N} \sum\limits_{i=1}^n L(y_i, f(x_i))$**
	- 期望风险 $R_{exp}(f)$ 是模型关于联合分布的期望损失，经验风险 $R_{emp}(f)$ 是模型关于训练样本集的平均损失。根据大数定律，当样本容量 $N -> \infty$， 经验风险 -> 期望风险。现实中训练样本数目有限，用经验风险估计期望风险尝尝不理想，要对经验风险进行一定的矫正。这就关系到监督学习的两个基本策略 **经验风险最小化、结构风险最小化**
- 经验风险最小化与结构风险最小化
	- 在假设空间、损失函数以及训练数据集确定的情况下，经验风险函数式就可以确定。经验风险最小化empirical risk minimization ERM 的策略认为，经验风险最小的模型是最优的模型，就是求解最优化问题 $\mathop{min}\limits_{f \in F}\frac{1}{N}\sum\limits_{i=1}^NL(y_i, f(x_i))$ ，其中，F是假设空间
		- 当样本容量足够大时，经验风险最小化由很好效果，极大似然估计maximum likelihood estimation就是经验风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数时，经验风险最小化 $\equiv$ 极大似然估计
		- 当样本容量很小时,会**过拟合over-fitting**
	- 结构风险最小化structural risk minimization SRM，是为了防止过拟合， $\equiv$ 正则化regularization。结构风险在经验风险上加上表示模型复杂度的正则化项regularizer或罚项penalty term。在假设空间、损失函数以及训练数据集确定的情况下， $R_{srm}(f) = \frac{1}{N}\sum\limits_{i=1}^NL(y_i, f(x_i))+\lambda J(f)$
		- 其中 $J(f)$ 为模型的复杂度，是定义在假设空间 F 上的泛函。模型 f 越复杂，复杂度 $J(f)$ 就越大；反之模型越简单，复杂度越小。复杂度表示可对复杂魔性的惩罚。
		-  $\lambda \geq 0$ 是系数，用以权衡经验风险和模型复杂度。结构风险小需要经验风险与模型复杂度同时小。结构风险小的模型往往对训练数据以及未知的测试数据都有较好的预测。
		- 贝叶斯估计中的最大后验概率估计maximum posterior probability estimation MAP，就是结构风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化 $\equiv$ 最大后验概率估计。
		- 就是求解最优化问题 $\mathop{min}\limits_{f \in F} \frac{1}{N} \sum\limits_{i=1}^{N}L(y_i, f(x_i)) + \lambda J(f)$
##### 算法
- 算法是指学习模型的具体计算方法
- 统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型
- 统计学习问题归结为最优化问题，统计学习的算法成为求解最优化问题的算法

#### 1.4 模型评估与模型选择
- 训练误差与测试误差
	- 统计学习的目的是使学到的模型不仅对已知数据而且对未知数据都能有好的预测能力。当损失函数给定时，基于损失函数的模型的训练误差training error和模型的测试误差test error就成为学习方法评估的标准。
	- 假设学习到的模型是 $Y = \hat{f}(X)$
		- 训练误差是模型 $Y = \hat{f}(X)$ 关于训练数据集的平均损失  $R_{emp}(\hat{f}) = \frac{1}{N}\sum\limits_{i=1}^{N}L(y_i, \hat{f}(x_i))$，其中 $N$ 是训练样本容量。
		- 测试误差是模型  $Y = \hat{f}(X)$ 关于测试数据集的平均损失  $e_{test} = \frac{1}{N'}\sum\limits_{i=1}^{N'}L(y_i, \hat{f}(x_i))$，其中 $N'$ 是测试样本容量
- 训练误差的大小，对判断给定的问题是不是一个容易学习的问题是有意义的，但本质上不重要
- 测试误差反映了学习方法对未知的测试数据集的预测能力，是学习中的重要概念，通常称为 **泛化能力generalization**

- 过拟合与模型选择
	- 当假设空间含有不同复杂度的模型时，面临模型选择model selection的问题。具体地，所选择的模型要与真模型的参数个数相同，所选择模型的参数向量与真模型的参数向量相近
	- 过拟合over-fitting，就是一味追求提高对训练数据的预测能力，所选模型的复杂度往往会比真模型更高。学习时选择的模型所包含的参数过多。

#### 1.5 正则化与交叉验证
- 正则化regularization，是模型选择的典型方法。
	- 正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项reguizer或罚项penalty term
	- 正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。
	- 正则化一般形式:  $\mathop{min}\limits_{f\in F}\frac{1}{N}\sum\limits_{i=1}^{N}L(y_i, f(x_i)) + \lambda J(f)$，其中，第1项是经验风险，第2项是正则化项， $\lambda \geq 0$ 为调整两者之间关系的系数
	- 正则化的作用是选择经验风险与模型复杂度同时较小的模型。符合奥卡姆剃刀Occam's Razor 原理，在所有可能选择的模型中，能够很好地解释已知数据并且十分简单才是最好的模型。从贝叶斯估计的角度来看，正则化项对应于模型的先验概率。可以假设复杂的模型由较小的先验概率，简单的模型有较大的先验概率。

- 交叉验证cross validation
	- 如果样本数据充足，简单方法是随机地将数据集切分成三部分，分别为训练集training set、验证集validation set 和测试集test set。
	- 交叉验证的基本思想是重复地使用数据；把给定的数据进行切分，将切分的数据集组合为训练集与测试集，在此基础上反复地进行训练、测试以及模型选择。
		1. 简单交叉验证，随机地将已给数据分为两部分，一部分作为训练集，另一部分作为测试集，一般七三开；然后用训练集在各种条件下训练模型，得到不同的模型；在测试集上评价各个模型的测试误差，选出最小的模型
		2. S 折交叉验证
