# 赛题背景

## [基于论文摘要的文本分类与关键词抽取挑战赛](https://​challenge​.xfyun​.cn​/topic​/info​?type​=​abstract​-of​-the​-paper​&​ch​=​ymfk4uU](https://challenge.xfyun.cn/topic/info?type=abstract-of-the-paper&ch=ymfk4uU)

-  医学领域的文献库中蕴含了丰富的疾病诊断和治疗信息，如何高效地从海量文献中提取关键信息，进行疾病诊断和治疗推荐，对于临床医生和研究人员具有重要意义。

## 赛题任务

-  机器通过对论文摘要等信息的理解，判断该论文是否属于医学领域的文献
-  任务示例：

-  输入：

>  论文信息，格式如下：
>   Inflammatory Breast Cancer: What to Know About This Unique, Aggressive Breast Cancer.，
>   [Arjun Menta, Tamer M Fouad, Anthony Lucci, Huong Le-Petross, Michael C Stauder, Wendy A Woodward, Naoto T Ueno, Bora Lim]，
>   Inflammatory breast cancer (IBC) is a rare form of breast cancer that accounts for only 2% to 4% of all breast cancer cases. Despite its low incidence, IBC contributes to 7% to 10% of breast cancer caused mortality. Despite ongoing international efforts to formulate better diagnosis, treatment, and research, the survival of patients with IBC has not been significantly improved, and there are no therapeutic agents that specifically target IBC to date. The authors present a comprehensive overview that aims to assess the present and new management strategies of IBC.，
>   Breast changes; Clinical trials; Inflammatory breast cancer; Trimodality care.

- 输出：

> 是(1)


## 赛题数据集

-  训练集与测试集数据为 CSV 格式文件，各字段分别是 _标题、作者、摘要、关键词_。

## 评价指标

-  本次竞赛的评价标准采用 F1_score，分数越高、效果越好。

## F1-score

-  F1-score 是分类问题的一个衡量指标。一些多分类的机器学习竞赛常采用。
-  __它是精确率和召回率的调和平均数，最大为 1， 最小为 0，值越大意味着模型越好。__
-  调和平均数： harmonic mean, 又称倒数平均数，是总体 _各统计变量倒数的算术平均数的倒数_。

### 定义概念

|        | 真实 1            | 真实 0            |
| ------ | ----------------- | ----------------- |
| 预测 1 | TP ture positive  | FP false positive |
| 预测 0 | FN false negative | TN true negative                  |

-  _Precision 查准率_  -  _预测值为 1 且 真实值也为 1_ 的样本在 _预测值为 1_ 的所有样本中所占的比例。
	-   $p = \frac{TP}{TP + FP}$
-  _Recall 召回率，也叫查全率_ -  指的是 _预测值为 1 且 真实值也为 1_ 的样本在 _真实值为 1_ 的所有样本中所占的比例
	-  $r = \frac{TP}{TP+FN}$

-  由此引出， $F1 = 2 \cdot \frac{precision \cdot recall}{precision + recall}$
-   更一般的是 $F_{\beta} = (1 + {\beta}^2) \cdot \frac{precision \cdot recall}{({\beta}^2 \cdot precision) + recall}$
-  意义：  $F_1$ 是 $F_{\beta}$ 是一种特殊形式， F1 认为 _召回率和准确率同等重要_， F2 认为 _召回率的重要程度是准确率的 2 倍_。

---

# 解题思路

![[Pasted image 20230817095520.png]]

-  针对文本分类任务，提供两种实践思路
	1.  使用传统的特征提取方法，如 TF-IDF 、BOW 结合机器学习模型
	2.  使用预训练的 BERT 模型进行建模

-  由上图可见， __特征提取 + 机器学习__ 的思路步骤：

1.  _数据预处理_  -  首先，对文本数据进行预处理，包括 文本清洗 (如去除特殊字符、标点符号)、分词等操作。可以使用常见的 NLP 工具包 (如 NLTK、spaCy) 来辅助进行预处理。
	   - https://github.com/dongrixinyu/JioNLP   中文预处理工具包
2.  _特征提取_  -  使用 TF-IDF 或 BOW 方法将文本转换为向量表示。
	-  TF - IDF 计算文本中词语的重要性
	-  BOW 则简单地统计每个词语在文本中的出现次数。
	-  可以使用 scikit-learn 库的 TfidfVectorizer 或 CountVectorizer 来实现特征提取。
3. _构建训练集和测试集_：将预处理后的文本数据分割为训练集和测试集，确保数据集的样本分布均匀。
4.  _选择机器学习模型_：根据实际情况选择适合的机器学习模型，如 Naive Bayes、 SVM、 Random Forrest 等。这些模型在文本分类任务中表现良好。可以使用 scikit-learn 苦衷相应的分类器进行模型训练和评估。
5.  _模型训练和评估_ ： 使用训练集对选定的机器学习模型进行训练，然后使用测试集进行评估。评估指标可以选择准确率、精确率、召回率、F1值等。
6.  _调参优化_ : 如果模型效果不理想，可以尝试调整特征提取的参数 (如 词频阈值、词袋大小等) 或机器学习模型的参数，以获得更好的性能。