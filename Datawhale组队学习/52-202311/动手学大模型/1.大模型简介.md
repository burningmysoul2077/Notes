- [前言](#--)
- [1. 发展历程](#1-----)
- [2. 大语言模型](#2------)
- [3 大模型的特殊之处](#3---------)
  * [3.1 涌现能力 emergence](#31------emergence)
  * [3.2 作为基座模型支持多元应用的能力](#32----------------)
  * [3.3 支持对话作为统一入口的能力](#33--------------)
  * [3.4 大模型的特点](#34-------)
- [4 常见大模型](#4------)
  * [4.1 封闭 LLM](#41----llm)
    + [GPT 系列](#gpt---)
    + [Claude 系列](#claude---)
    + [PaLM 系列](#palm---)
    + [文心一言](#----)
    + [星火大模型](#-----)
  * [4.2 开源LLM](#42---llm)
    + [LLaMA 系列](#llama---)
    + [GLM 系列](#glm---)
    + [通义千问](#----)
    + [Baichuan 系列](#baichuan---)
- [5 LangChain](#5-langchain)
  * [5.1 LangChain 简介](#51-langchain---)
  * [5.2 发展历史](#52-----)
  * [核心组件](#----)

---

# 前言

-  大语言综述 - 《[A_Survey_of_LLM_阅读](https://github.com/burningmysoul2077/Notes/blob/main/LLM%E5%AE%87%E5%AE%99/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%BB%BC%E8%BF%B0_A_Survey_of_LLM_%E9%98%85%E8%AF%BB.md)》

# 1. 发展历程

-  20 世纪 90 年代，开始语言建模。最初采用 _统计学习方法_，通过前面的词汇来预测下一个词汇。
-  2003 年， Bengio 在他的经典论文 [《[A Neural Probabilistic Language Model-阅读](https://github.com/burningmysoul2077/Notes/blob/main/LLM%E5%AE%87%E5%AE%99/Bengio_A_Neural_Probabilistic_Language_Model_%E9%98%85%E8%AF%BB.md)》] 中，首次将深度学习的思想融入到语言模型中，采用了 _神经网络模型_ 。
-  2018 年，诞生了 Transformer 架构的神经网络模型，通过大量文本数据训练模型。
-   随着语言模型规模的扩大，包括增加模型大小或使用更多数据，模型展现出惊人的能力，这时进入了大语言模型时代。

# 2. 大语言模型

>  大语言模型 Large Language Model，指包含数百亿或更多参数的语言模型。

-  国外的有GPT-3 、GPT-4、PaLM 、Galactica 和 LLaMA 等，国内的有ChatGLM、文心一言、通义千问、讯飞星火等

-  LLM已经在许多领域产生了深远的影响。在**自然语言处理**领域，它可以帮助计算机更好地理解和生成文本，包括写文章、回答问题、翻译语言等。在**信息检索**领域，它可以改进搜索引擎，让我们更轻松地找到所需的信息。在**计算机视觉**领域，研究人员还在努力让计算机理解图像和文字，以改善多媒体交互。

-  最重要的是，LLM的出现让人们重新思考了 **通用人工智能（AGI）** 的可能性。AGI 是一种像人类一样思考和学习的人工智能。LLM 被认为是 AGI 的一种早期形式，这引发了对未来人工智能发展的许多思考和计划。

# 3 大模型的特殊之处

## 3.1 涌现能力 emergence

-  区分 LLM 与 PLM 最显著的特征之一就是 _涌现能力_，它可以类比到物理学中的相变现象，也就是我们常说的量变引起了质变。
-  涌现能力可以定义为与某些复杂任务相关的能力，但我们更关注的是它们具备的通用能力，下面介绍三个典型的涌现能力：
1. 上下文学习。 GPT-3 首次引入，通过理解上下文并生成相应的输出的方式来执行任务，而无需额外的训练或参数更新。
2.  指令遵循。通过使用自然语言描述的多任务数据进行微调，也就是所谓的指令微调。LLM 被证明在同样使用指令形式化描述的未见过的任务上表现良好。这意味着LLM能够根据任务指令执行任务，而无需事先见过具体示例，这展示了其强大的泛化能力。
3.  逐步推理。小型语言模型通常难以解决涉及多个推理步骤的复杂任务，例如数学问题。然而，LLM通过采用 "_思维链_" 推理策略，可以利用包含中间推理步骤的提示机制来解决这些任务，从而得出最终答案。据推测，这种能力可能是通过对代码的训练获得的。

## 3.2 作为基座模型支持多元应用的能力

-  2021 年，Stanford 提出了 _基座模型 foundation model_，更清晰地描述了预训练模型的作用，这是一种全新的 AI 技术范式。记住与海量无标注数据的训练，获得可以适用于大量下游任务的大模型 (单模态/多模态)

## 3.3 支持对话作为统一入口的能力

-  ChatGPT 让世人真正见识到了大语言模型。这引发我们对于智能体 Agent 类型应用前景的思考。

## 3.4 大模型的特点

1.  超大的规模：数十亿甚至数千亿个参数。
2.  预训练和微调
3.  上下文感知
4.  多语言支持
5.  多模态支持
6.  涌现能力
7.  多领域应用
8.  伦理和风险问题

---

# 4 常见大模型

![imagetext](https://raw.githubusercontent.com/burningmysoul2077/Notes/main/ScreenShots/Datawhale%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/Pasted%20image%2020231114135038.png)

## 4.1 封闭 LLM

### GPT 系列

![imagetext](https://raw.githubusercontent.com/burningmysoul2077/Notes/main/ScreenShots/Datawhale%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0/Pasted%20image%2020231114135123.png)


### Claude 系列

-  Claude 系列模型是由 OpenAI 离职人员创建的 **Anthropic** 公司开发的闭源语言大模型。

### PaLM 系列

-  **PaLM 系列**语言大模型由 **Google** 开发。

### 文心一言

-  文心一言是基于百度文心大模型的知识增强语言大模型。

### 星火大模型


## 4.2 开源LLM

### LLaMA 系列

-  **LLaMA 系列模型**是 Meta 开源的一组参数规模 **从 7B 到 70B** 的基础语言模型，它们都是在数万亿个字符上训练的，展示了如何**仅使用公开可用的数据集来训练最先进的模型**，而不需要依赖专有或不可访问的数据集。

### GLM 系列

-  **GLM 系列模型是清华大学和智谱 AI 等合作研发的开源语言大模型**。`ChatGLM` 是基于 GLM 结构开发的具有 **62 亿参数量**的语言大模型，**支持 2048 的上下文长度**。

### 通义千问

-  **通义千问由阿里巴巴基于“通义”大模型研发**，于 2023 年 4 月正式发布。2023 年 8 月，阿里云开源了Qwen（通义千问）系列工作，当前开源模型的参数规模为70亿（7B）和140亿（14B）。

### Baichuan 系列

-  **Baichuan** 是由**百川智能**开发的**开源可商用**的语言大模型，在权威的中文和英文 benchmark 上均取得同尺寸最好的效果，其基于**Transformer 解码器架构**。

---

# 5 LangChain

## 5.1 LangChain 简介

-  LangChain 框架是一个开源工具，充分利用了大型语言模型的强大能力，以便开发各种下游应用。它的目标是为各种大型语言模型应用提供通用接口，从而简化应用程序的开发流程。

## 5.2 发展历史

-  LangChain 的作者是 Harrison Chase，该项目 2022 年 10 月在 github 上开源。

## 核心组件

-  LangChian 作为一个大语言模型开发框架，可以将 LLM 模型（对话模型、embedding模型等）、向量数据库、交互层 Prompt、外部知识、外部代理工具整合到一起，进而可以自由构建 LLM 应用。 

-  LangChain 主要由以下 6 个核心模块组成:
1.  **模型输入/输出（Model I/O）**：与语言模型交互的接口
2.  **数据连接（Data connection）**：与特定应用程序的数据进行交互的接口
3.  **链（Chains）**：将组件组合实现端到端应用。
4.  **记忆（Memory）**：用于链的多次运行之间持久化应用程序状态；
5.  **代理（Agents）**：扩展模型的推理能力。用于复杂的应用的调用序列；
6. **回调（Callbacks）**：扩展模型的推理能力。用于复杂的应用的调用序列；