# 1 验证迭代的一般思路

-  如果使用传统方法开发 LLM 应用，很可能出现的场景：
1. 会在 1 到 3 个的小样本中调整 Prompt，尝试使其在这些样本上起效。
2.  随后，对系统进一步测试时，很可能会遇到一些棘手的例子，这些例子无法通过 Prompt 或者算法解决。
-  这就是使用 LLM 构建应用程序的开发者所面临的挑战。

-  在这种情况下，你可以将这些额外的几个例子添加到你正在测试的集合中，有机地添加其他难以处理的例子。最终，你会将足够多的这些例子添加到你逐步扩大的开发集中，以至于手动运行每一个例子以测试 Prompt 变得有些不便。然后，你开始开发一些用于衡量这些小样本集性能的指标，例如平均准确度。这个过程的有趣之处在于，如果你觉得你的系统已经足够好了，你可以随时停止，不再进行改进。实际上，很多已经部署的应用程序就在第一步或第二步就停下来了，而且它们运行得非常好。

## 1.1 一般流程

>  验证迭代是构建以 LLM 为中心的应用程序所必不能少的重要步骤，通过不断寻找 Bad Case，针对性调整 Prompt 或优化应用框架，来推动应用达到我们目标中的性能与精度。

![[Pasted image 20231123144930.png]]


### Prompt Engineering 

-  在上一章 Prompt Engineering 部分，我们已经讲解了如何在数个简单样例的基础上设计 Prompt Engineering，初步实现核心任务的启动。

### Bad Case

-  我们将首先介绍如何找出 Bad Case 的一些思路提示，以及针对 Bad Case 针对性做出 Prompt 优化的一般思路。注意，在这一过程中，你仍然应该谨记我们在上一节中所讲述的 Prompt 设计原则与技巧，并时刻保证优化后的 Prompt 不会在原先表现良好的样例上出现失误。

### 自动评估

-  接着介绍大模型开发评估的几种方法。对于有简单标准答案的任务来说，评估很容易得到实现；但大模型开发一般是需要实现复杂的生成任务，如何在没有简单答案甚至没有标准答案的情况下实现评估，能够准确地反映应用的效果。

-  最后，随着我们不断寻找到 Bad Case 并做出针对性优化，我们可以将这些 Bad Case 逐步加入到验证集，从而形成一个有一定样例数的验证集。针对这种验证集，一个一个进行评估就是不切实际的了。我们需要一种自动评估方法，实现对该验证集上性能的整体评估。

---

# 2 解决 Bad Case

## 2.1 构造向量数据库

-  使用之前构造的本地持久化的向量数据库
-  再引入智谱 AI Embedding
-  最后使用 LangChain PromptTemplate

![[Pasted image 20231123154346.png]]

-  可以查看检索到的相关文本

![[Pasted image 20231123154755.png]]

## 2.2 提升直观回答质量


>  寻找 Bad Case 的思路有很多，最直观也最简单的就是评估直观回答的质量，结合原有资料内容，判断在什么方面有所不足。

-  尝试把上一小节测试改造成一个 Bad Case。

```
问题：什么是神经网络
初始回答：" 神经网络是一种由人工神经元和神经元之间的连接构成的信息处理系统，其中有两类特殊的神经元：一类用来接收外部的信息，另一类用来输出信息。神经网络可以看作是从输入到输出的信息处理系统。"
存在不足：回答太笼统，需要回答更具体；谢谢你的提问感觉比较死板，可以去掉
```

-  第二个模板果然回答丰富了很多。

![[企业微信截图_17007261113037.png]]

- 更进一步思考，要求模型给出具体、详细的回答，是否会导致针对一些有要点的回答没有重点、模糊不清？我们测试以下问题：

![[Pasted image 20231123161805.png]]